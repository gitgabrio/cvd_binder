{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is an example of a Python notebook used to train a model (decision tree) and then export it as PMML so that it can be easily integrated with additional decision logic (DMN https://drools.org/learn/dmn.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case: credit card dispute risk\n",
    "In this example end user has filed a credit card dispute and we want to predict the risk related to the disputed transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "To run this notebook you need to have:\n",
    "- Python 3 https://www.python.org/downloads/\n",
    "- Pip https://pypi.org/project/pip/\n",
    "- jupyter https://jupyter.org/ (`pip install jupyterlab`)\n",
    "\n",
    "Install dependencies:\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- numpy\n",
    "- nyoka\n",
    "- matplotlib\n",
    "\n",
    "All of them can be installed cloning this repo and using command `pip install -r ./binder/requirements.txt`\n",
    "\n",
    "Finally start the environment using the command `jupyter notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nyoka import skl_to_pmml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Load and prepare data\n",
    "Data are usually available as unstructure files with text (csv) or binary (parquet, avro) format and there are many libraries to load them from a local or remote storage.\n",
    "\n",
    "After the loading step it is quite common to perform some preparation/cleanup actions: check domain boundaries, handle missing values, normalize strings, convert enumaration to number, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>buyed_items</th>\n",
       "      <th>type_index</th>\n",
       "      <th>buyed_customer_items_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Book</td>\n",
       "      <td>[Book-2, Book-3, Book-5, Book-6, Book-7, Book-9]</td>\n",
       "      <td>0</td>\n",
       "      <td>1101110100000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book</td>\n",
       "      <td>[Book-1, Book-2, Book-3, Book-5, Book-6, Book-7]</td>\n",
       "      <td>0</td>\n",
       "      <td>11101110000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Book</td>\n",
       "      <td>[Book-0, Book-1, Book-4, Book-5, Book-8, Book-9]</td>\n",
       "      <td>0</td>\n",
       "      <td>110011001100000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Book</td>\n",
       "      <td>[Book-0, Book-2, Book-3, Book-4, Book-6, Book-7]</td>\n",
       "      <td>0</td>\n",
       "      <td>101110110000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Book</td>\n",
       "      <td>[Book-2, Book-4, Book-5, Book-6, Book-8, Book-9]</td>\n",
       "      <td>0</td>\n",
       "      <td>1011101100000000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                       buyed_items  type_index  \\\n",
       "0  Book  [Book-2, Book-3, Book-5, Book-6, Book-7, Book-9]           0   \n",
       "1  Book  [Book-1, Book-2, Book-3, Book-5, Book-6, Book-7]           0   \n",
       "2  Book  [Book-0, Book-1, Book-4, Book-5, Book-8, Book-9]           0   \n",
       "3  Book  [Book-0, Book-2, Book-3, Book-4, Book-6, Book-7]           0   \n",
       "4  Book  [Book-2, Book-4, Book-5, Book-6, Book-8, Book-9]           0   \n",
       "\n",
       "          buyed_customer_items_id  \n",
       "0    1101110100000000000000000000  \n",
       "1   11101110000000000000000000000  \n",
       "2  110011001100000000000000000000  \n",
       "3  101110110000000000000000000000  \n",
       "4    1011101100000000000000000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input_data.csv')\n",
    "df.buyed_items = df.buyed_items.str[1:-1].str.replace(\"'\",'').str.replace(\",\",'').str.split(' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 2 - Prepare training set and test set\n",
    "When a model is trained, it is important to use different set of data to train and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#raw_inputs_grouped = pd.DataFrame(df['buyed_items'])\n",
    "#print(raw_inputs_grouped)\n",
    "#raw_inputs = pd.DataFrame(raw_inputs_grouped.buyed_items.tolist(), index = raw_inputs_grouped.index)\n",
    "#print(raw_inputs)\n",
    "\n",
    "#d1 = [['Book-0', 'Car-0', 'PC-0'], ['Book-1', 'Car-1', 'PC-1'],['Book-2', 'Car-2', 'PC-2'],['Book-3', 'Car-3', 'PC-3'],['Book-4', 'Car-4', 'PC-4'],['Book-5', 'Car-5', 'PC-5'],['Book-6', 'Car-6', 'PC-6'],['Book-7', 'Car-7', 'PC-7'],['Book-8', 'Car-8', 'PC-8'],['Book-9', 'Car-9', 'PC-9']]\n",
    "#d2 = [['Book-0', 'Book-1', 'Book-2', 'Book-3', 'Book-4', 'Book-5', 'Book-6', 'Book-7', 'Book-8', 'Book-9'], ['Car-0', 'Car-1', 'Car-2', 'Car-3', 'Car-4', 'Car-5', 'Car-6', 'Car-7', 'Car-8', 'Car-9'],['PC-0', 'PC-1', 'PC-2', 'PC-3', 'PC-4', 'PC-5', 'PC-6', 'PC-7', 'PC-8', 'PC-9']]\n",
    "\n",
    "\n",
    "#books = ['Book-0', 'Book-1', 'Book-2', 'Book-3', 'Book-4', 'Book-5', 'Book-6', 'Book-7', 'Book-8', 'Book-9']\n",
    "#cars = ['Car-0', 'Car-1', 'Car-2', 'Car-3', 'Car-4', 'Car-5', 'Car-6', 'Car-7', 'Car-8', 'Car-9']\n",
    "#pcs = ['PC-0', 'PC-1', 'PC-2', 'PC-3', 'PC-4', 'PC-5', 'PC-6', 'PC-7', 'PC-8', 'PC-9']\n",
    "#enc = preprocessing.OneHotEncoder(categories=[books, cars, pcs])\n",
    "\n",
    "#enc.fit(d2)\n",
    "#inputs = enc.transform([['Book-0', 'Book-1', 'Book-4']]).toarray()\n",
    "#print(inputs)\n",
    "\n",
    "\n",
    "inputs = df[['type_index', 'buyed_customer_items_id']]\n",
    "#print(inputs)\n",
    "\n",
    "#d1 = {'teams': [[0, 1, 0],[0, 1, 0],[0, 1, 0], [0, 1, 0],[0, 1, 0]]}\n",
    "#df2 = pd.DataFrame(d1)\n",
    "#print (df2)\n",
    "\n",
    "#df2  = pd.DataFrame(inputs.buyed_customer_items_id.tolist(), index=inputs.index)\n",
    "\n",
    "#print (df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# Step 3 - Train the model\n",
    "There are many different models that can be used. In this example we will use a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"classifier\", KMeans(n_clusters=3, random_state=0))\n",
    "])\n",
    "trained_model = pipeline.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Test the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple way to test the model, first of all you should test it using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_score: -4.9763407397121e+57\n"
     ]
    }
   ],
   "source": [
    "model_score = trained_model.score(inputs)\n",
    "print(\"model_score: \" + str(model_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Pay attention to overfitting problem ( https://en.wikipedia.org/wiki/Overfitting )  while you train and test your model. For example a score of 0.99 or similar is an important sign of a probable overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally you can print to visually compare predicted data with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    type_index         buyed_customer_items_id\n",
      "0            0  110001110100000000000000000000\n",
      "1            0  111011001000000000000000000000\n",
      "2            0  101111100000000000000000000000\n",
      "3            0  101011110000000000000000000000\n",
      "4            0  110100110100000000000000000000\n",
      "5            0  111011000100000000000000000000\n",
      "6            0   11100110100000000000000000000\n",
      "7            0   11010110100000000000000000000\n",
      "8            0    1111100100000000000000000000\n",
      "9            0  110111010000000000000000000000\n",
      "10           0   11110011000000000000000000000\n",
      "11           0  110110101000000000000000000000\n",
      "12           0  110111100000000000000000000000\n",
      "13           0    1101101100000000000000000000\n",
      "14           0  111010010100000000000000000000\n",
      "15           0  100110110100000000000000000000\n",
      "16           1            11011011000000000000\n",
      "17           1             1101100110000000000\n",
      "18           1             1100111100000000000\n",
      "19           1            10111001010000000000\n",
      "20           1                1111110000000000\n",
      "21           1            11110100010000000000\n",
      "22           1             1101110010000000000\n",
      "23           1             1001011110000000000\n",
      "24           1            10111010010000000000\n",
      "25           1            10111010100000000000\n",
      "26           1              101101110000000000\n",
      "27           1            11101011000000000000\n",
      "28           1             1111001010000000000\n",
      "29           1            11001011010000000000\n",
      "30           1             1101110010000000000\n",
      "31           1            10101010110000000000\n",
      "32           1            10011010110000000000\n",
      "33           2                      1111001010\n",
      "34           2                       101011011\n",
      "35           2                      1001101101\n",
      "36           2                      1100011101\n",
      "37           2                         1110111\n",
      "38           2                      1000111110\n",
      "39           2                       111011010\n",
      "40           2                      1000111110\n",
      "41           2                      1100011110\n",
      "42           2                       100111101\n",
      "43           2                       101110011\n",
      "44           2                       101001111\n",
      "45           2                       101101101\n",
      "46           2                       100110111\n",
      "47           2                        11100111\n",
      "48           2                       111100101\n",
      "    cluster prediction                           truth\n",
      "0                    1  110001110100000000000000000000\n",
      "1                    1  111011001000000000000000000000\n",
      "2                    1  101111100000000000000000000000\n",
      "3                    1  101011110000000000000000000000\n",
      "4                    1  110100110100000000000000000000\n",
      "5                    1  111011000100000000000000000000\n",
      "6                    2   11100110100000000000000000000\n",
      "7                    2   11010110100000000000000000000\n",
      "8                    0    1111100100000000000000000000\n",
      "9                    1  110111010000000000000000000000\n",
      "10                   2   11110011000000000000000000000\n",
      "11                   1  110110101000000000000000000000\n",
      "12                   1  110111100000000000000000000000\n",
      "13                   0    1101101100000000000000000000\n",
      "14                   1  111010010100000000000000000000\n",
      "15                   1  100110110100000000000000000000\n",
      "16                   0            11011011000000000000\n",
      "17                   0             1101100110000000000\n",
      "18                   0             1100111100000000000\n",
      "19                   0            10111001010000000000\n",
      "20                   0                1111110000000000\n",
      "21                   0            11110100010000000000\n",
      "22                   0             1101110010000000000\n",
      "23                   0             1001011110000000000\n",
      "24                   0            10111010010000000000\n",
      "25                   0            10111010100000000000\n",
      "26                   0              101101110000000000\n",
      "27                   0            11101011000000000000\n",
      "28                   0             1111001010000000000\n",
      "29                   0            11001011010000000000\n",
      "30                   0             1101110010000000000\n",
      "31                   0            10101010110000000000\n",
      "32                   0            10011010110000000000\n",
      "33                   0                      1111001010\n",
      "34                   0                       101011011\n",
      "35                   0                      1001101101\n",
      "36                   0                      1100011101\n",
      "37                   0                         1110111\n",
      "38                   0                      1000111110\n",
      "39                   0                       111011010\n",
      "40                   0                      1000111110\n",
      "41                   0                      1100011110\n",
      "42                   0                       100111101\n",
      "43                   0                       101110011\n",
      "44                   0                       101001111\n",
      "45                   0                       101101101\n",
      "46                   0                       100110111\n",
      "47                   0                        11100111\n",
      "48                   0                       111100101\n"
     ]
    }
   ],
   "source": [
    "dfsimple = pd.read_csv('simple_input_data.csv')\n",
    "test_inputs = dfsimple[['type_index', 'buyed_customer_items_id']]\n",
    "print(test_inputs)\n",
    "\n",
    "predictions = trained_model.predict(test_inputs)\n",
    "results = pd.DataFrame({'cluster prediction': predictions.astype(int),\n",
    "                        'truth': test_inputs['buyed_customer_items_id']})\n",
    "#results.head(30)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to plot predicted data and real data on the same chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-497ceb22ba95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"figure.figsize\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtype_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'items_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type_index'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype_index\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_test' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = trained_model.predict(input_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "type_index = 2\n",
    "testing = pd.DataFrame({'items_id': np.linspace(0, input_test['items_id'].max(), 100), 'type_index': type_index})\n",
    "sub_test = df[df['type_index']==type_index]\n",
    "\n",
    "DT_predictions = trained_model.predict(testing).astype(int)\n",
    "plt.subplot(121)\n",
    "plt.plot(testing['items_id'], DT_predictions, color='red', label='Predicted')\n",
    "plt.scatter(sub_test['items_id'], sub_test['buyer_group'], color='black', label='truth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring and visualization are just simple ways to test the trained model. They are usually not enough for real world use cases.\n",
    "\n",
    "There are advanced way to analyze how the model is performing (i.e. ROC) and there are many other aspects to consider: fairness, explanability, interpretability.\n",
    "\n",
    "Additional resources:\n",
    "- https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "- https://christophm.github.io/interpretable-ml-book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Save the model as PMML\n",
    "When your are happy with your model you can export it as PMML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_to_pmml(trained_model, ['items_id', 'type_index'], 'buyer_group',\n",
    "                \"cluster_buyer_predictor.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
